\chapter{Security Allgemein}

Bevor wir konkret die Sicherheit von Webapplikationen betrachten können, müssen einige Grundbegriffe geklärt werden.

Die primäre Frage bei einer Sicherheitsdiskussion ist die Frage, was überhaupt beschützt werden sollte. Diese Operationen oder Daten werden häufig \textit{Schützenswertes Gut} genannt. Beispiele für diese sind z. B. sensible Benutzerdaten, ein essentieller Geschäftsprozess aber auch immaterielle Werte wie die Reputation eines Unternehmens, dessen Aktienkurs, IP (intellectual property) oder auch die Aufmerksamkeit/Achtsamkeit des Personals sein. Prinzipiell wird die sog. CIA-Triad zur Klassifizierung verwendet. Die einzelnen Buchstaben stehen für:

\begin{itemize}
	\item Confidentiality: no unauthorized access to data
	\item Integrity: no unauthorized or undetected\footnote{Mittels Hashes, MACs, Verschlüsselung, etc. können prinzipiell Veränderungen nicht verhindert werden, allerdings können Veränderungen im Nachhinein detektiert werden.} modification
	\item Availability: Verfügbarkeit der Daten
\end{itemize}

Die jeweiligen Bereiche sind miteinander verwandt, Availability kann stark von der Integrität der Daten abhängig sein. Beispiel: wenn eine Fahrzeitauskunft zwar als Webservice verfügbar ist, aber den Daten nicht vertraut werden kann, ist das Gesamtservice aus Usersicht wahrscheinlich nicht available.

Bei realen Projekten ist die Einschätzung immer vom Kunden abhängig. Ein IT-System ist immer in die Kundenlandschaft integriert und daher können klassische IT-Fehler unterschiedliche Auswirkungen besitzen. Z. B. wird einem reinen Online-Shop die Availability wichtiger sein, als einem physikalischen Shop der nebenbei einen kleinen Onlineshop betreibt; teilweise werden Fehler durch organisatorische Maßnahme (Buchhaltung) abgefangen, etc.

\section{Sicherheit als Prozess}

Sicherheit ist keine One-Shot Operation, die einmalig vor Projektende durchgeführt wird, sondern muss während der gesamten Laufzeit der Softwareentwicklung beachtet werden. Professionelle Softwareentwicklung verwendet meistens einen (semi-)standardisierten Software Development Lifecycle (SDLC), es gibt verschiedene Ausprägungen bei diesem Security einzubringen.

Zumeist werden in den jeweiligen Phasen sicherheitsrelevante Inhalte hinzugefügt:

\begin{itemize}
	\item Security Training
	\item Requirements and Risk Analysis
	\item Security Design Review, Threat Modeling
	\item Secure Coding Guidelines, Secure Coding Checklists
	\item Security Testing Guides, Pen-Tests
	\item Vulnerability Management and Incident Response
\end{itemize}

Einige dieser Punkte werden in den Folgekapiteln etwas genauer erläutert.

\subsection{Requirementsanalyse}

In der \textit{Requirementsanalyse} sollte bereits Security berücksichtigt werden. Dies wird meistens unterlassen, da Security-Anforderungen non-functional\footnote{Functional Requirements beschreiben die Funktionsweise einer Applikation und sind z. B. mittels use-cases abgebildet. Non-Functional Requirements beschreiben eher die Qualität der erstellen Applikation wie Sicherheit und Performance.} requirements sind. Negative Auswirkungen dieses Versäumnis sind fehlende Awareness für Security, nicht ausreichende Ressourcen (Zeit, Personal, Budget) und schlussendlich fehlende Sicherheit im resultierenden Softwareprodukt.

\subsection{Sicheres Design}

Bei der Erstellung der Software Architektur/des Software Designs sollte auf Sicherheit geachtet werden. Um die Ziele der CIA-Triad zu erfüllen, empfehlt OWASP folgende Elemente bei der Analyse eines sicheren Designs zu beachten:

\begin{itemize}
	\item Authentication
	\item Authorization
	\item Data Confidentiality and Integrity
	\item Availability
	\item Auditing and Non-Repudiation
\end{itemize}

Audit Logs dienen u.a. dazu, um im Fehlerfall die Schwachstelle zu erkennen als auch den Schadfall einzugrenzen (z. B. welche User sind in welchem Umfang betroffen?). Unter Non-Repudiation versteht man die Nicht-Abstreitbarkeit: falls eine Operation von einem Benutzer durchgeführt wurde, sollte nachträglich auch verifizierbar sein, dass diese Operation auch wirklich von dem jeweiligen Benutzer in Auftrag gegeben wurde.

\subsection{Threat Modeling}

Threat Models dienen zur systematischen Analyse von Softwareprodukten auf Risiken, Schwachstellen und Gegenmaßnahmen. Durch die Verwendung eines formalisierten Ablaufs wird die gleichbleibende Qualität der Analyse gewährleistet.

Bei der Analyse sollten vier Hauptfragen gestellt und beantwortet werden\footnote{Quelle: Adam Shostack --- Threat Modeling}:

\begin{enumerate}
	\item What are you building?
	\item What could go wrong?
	\item What should you do about those things that could go wrong?
	\item Did you do a decent job of analysis?
\end{enumerate}

Bevor auf diese einzelnen Bereiche kurz eingegangen wird sollte noch kurz erwähnt werden, dass Threat Models im Laufe der Zeit sehr umfangreich und daher schwer zu verstehen werden. Im Worst-Case wird es so ``aufgebauscht'' dass es nicht mehr effektiv verwendbar ist und schlussendlich nur noch ``tote'' Dokumentation darstellt. Ein guter Mittelweg zwischen Detailiertheit und Lesbarkeit ist essentiell für ein verwendbares Threat Model.

\subsubsection{What are you building?}

Folgende Bereiche sollten durch das Threat Model abgedeckt werden:

\begin{itemize}
	\item Threat Actors: wer sind die potentiellen Angreifer. Dies ist wichtig zu wissen, da dadurch eine bessere Ressourceneinschätzung (wie viel Zeit/finanzielle Ressourcen kann ein Angreifer aufbringen?) möglich ist. Ebenso wird dadurch geklärt, ob auch Insider-Angriffe möglich sind.
	\item Schützenswertes Gut: vor welchen Angriffen hat ein Unternehmen Angst bzw. welche Daten sind schützenswert. Die Dokumentation schützenswerter Güter ergibt Synergie-Effekte zu der notwendigen DSGVO-Dokumentation.
	\item Grundlegende Sicherheitsannahmen: im Laufe eines Softwareprojektes werden Produktentscheidungen aufgrund des aktuellen Wissensstand getroffen. Hier sollten diese Entscheidungen dokumentiert\footnote{Bonuspunkte wenn nicht nur die Annahme, sondern zusätzlich auch die Auswirkungen im Falle einer gebrochenen Annahme, wer für die Überprüfung der Annahme zuständig ist, und wer fachlich die Annahme überprüfen kann, dokumentiert ist.} werden. Beispielsweise könnte für embedded systems eine schwächere Verschlüsselungstechnik gewählt worden sein, da die vorhandene Hardware nicht potent genug für ein besseres Verfahren war. Durch die Dokumentation der Annahmen können diese periodische auf ihre Haltbarkeit hin überprüft werden. Die Dokumentation dieser Annahmen ist auch essentiell im Falle des Ausfalls eines Entwicklungsteams.
	\item Scope: welche Bereiche unterliegen der Sicherheitsobacht des Entwicklers? Ist die Datenbank, der Webserver, etc. Teil des Projekts oder werden diese von externen Personen bereitgestellt?
	\item Komponenten und Datenflüsse: die Applikation wird in einzelne Komponenten de-konstruiert. Der Datenfluss (samt Klassifizierung der betroffenen Daten) zwischen den Komponenten wird meistens mittels Datenflussdiagrammen (data flow diagrams, DFDs) dargestellt.
\end{itemize}

\subsubsection{What could go wrong?}

Basierend auf den Datenflussdiagrammen werden potentielle Risiken und Schwachstellen identifiziert. Häufig wird hierfür STRIDE verwendet. Jeder Buchstabe dieser Abkürzung steht für eine Angriffsart, durch das Analysieren jedes Elements (des Datenflussdiagrammes) sollten möglichst viele Gefährdungen identifiziert werden:

\begin{itemize}
	\item Spoofing
	\item Tampering
	\item Repudiation
	\item Information Disclosure
	\item Denial of Service
	\item Elevation of Privilege
\end{itemize}

Im Privacy Umfeld existiert mit LINDDUM eine ähnliche Methode, hierbei stehen die jeweiligen Buchstaben für:

\begin{itemize}
	\item Linkability
	\item Identifiability
	\item Non-Repudiation
	\item Detectability
	\item Disclosure of Information
	\item Content Unawareness
	\item Policy and Consent Noncompliance
\end{itemize}

Teilweise sind diese Methoden widersprüchlich.

\subsubsection{What should you do about those things that could go wrong?}

Die identifizierten Gefährdungen können dann mittels DREAD quantifiziert und sortiert. Diese Reihenfolge kann bei der Behebung der identifizierten Gefährdungen durch das Entwicklungsteam berücksichtigt werden.

Prinzipiell gibt es mehrere Möglichkeiten mit einer Schwachstelle umzugehen:

\begin{itemize}
	\item Elemination: die Schwachstelle wird entfernt --- dies ist effektiv nur durch Entfernen von Features möglich.
	\item Mitigation: es werden Maßnahmen implementiert die das Ausnutzen der Schwachstelle vermeiden bzw. erschweren sollen. Die meisten implementierten Sicherheitsmaßnahmen fallen in diesen Bereich.
	\item Transfer: durch Versicherungen und Verträge kann das Risiko an Andere übertragen werden.
	\item Accept: ein Risiko kann auch (durch die Geschäftsführung) akzeptiert werden. In diesem Fall ist die Dokumentation der Zuständigkeiten wichtig.
\end{itemize}

\subsubsection{Did we do a decent job of analysis?}

Die Ausarbeitung eines Threat Models macht Sinn wenn das Model mit der realen Applikation übereinstimmt und durch die sorgfältige Analyse der Elemente des Models Verwundbarkeiten identifiziert wurden. Die gefundenen Gefährdungen sollten in das Bug-Tracking System der Software einfließen um ein Tracking des Fortschritts zu ermöglichen.

Wird im Zuge des Softwareprojekts automatisiert getestet wird empfohlen, mittels Unit Tests die implementierten Mitigations zu verifizieren. Dadurch wird der Security Test Teil der Continues-Integration Pipeline und damit Teil der Qualitätssicherung der Software.

Zusätzlich können Penetration Tests zur Überprüfung der Sicherheit durchgeführt werden. Penetration Tests können Sicherheitsmängel aufdecken, sie sind allerdings nicht zur gezielten Erhöhung der Softwarequalität dienlich, da diese vor dem Testen bereits gewährleistet werden sollte (\textit{You can't test quality in}). Auch hier gibt es eine Interaktion mit dem Threat Model: während ein Threat Model im Gegensatz zu Penetration-Tests weniger direkte Sicherheitslücken findet, richtet es den Fokus der Penetration-Tests auf die wichtigsten bzw. gefährdetsten Komponenten der zu testenden Applikation.

\subsection{Secure Coding}

Während der Entwicklung sollte durch folgende Maßnahmen die Sicherheit der erstellten Software gewährleistet werden: 

\begin{itemize}
	\item Verwendung von Secure Coding Guidelines
	\item Einhaltung von Best-Practises
\end{itemize}

Der Großteil dieser Maßnahmen zielt darauf ab, nicht das Rad neu zu erfinden. Durch Verwendung etablierter Methodiken und Frameworks kann auf den Erfahrungsschatz dieser zugegriffen werden und potentielle Fehler vermieden werden.

Bei der Wahl von Bibliotheken und Frameworks sollte man auf deren Security-Historie Rücksicht nehmen. Regelmäßige Bugfix-Releases mit dezidierten Security-Releases sind ein gutes Zeichen. Ebenso sind dies regelmäßige Security-Audits. Falls keine Sicherheitsinformationen verfügbar sind oder die Bibliothek/das Framework keinen langfristigen Support gewährleistet, ist dies ein Grund ggf. dieses Framework nicht zu verwenden.

Das Sicherheitslevel kann durch Verwendung von Secrurity-Checklists überprüft werden. Ein Beispiel hierfür ist der OWASP Application Security Verfication Standard (ASVS) welcher aus einem Fragenkatalog zur Selbstbeantwortung durch Softwareentwickler besteht.

\subsection{Secure Testing}

Es sollte so früh wie möglich und regelmäßig wie möglich getestet werden. Zumindest vor größeren Releases sollte ein Security-Check durchgeführt werden.

Hierbei gibt es eine Interaktion mit Threat Modeling: aufgrund des Threatmodels können besonders gefährdete Bereiche identifiziert, und diese Bereiche gezielt getestet werden. Dadurch werden die Kosten des Testens reduziert.

\subsection{Maintenance}

Auch nach dem Abschluss der Entwicklungsphase eines Projektes gibt es Security-Anforderungen. Es sollte dokumentiert werden, wie im Falle eines Security-Vorfalls (Security Incident) vorgegangen wird. Dieser Prozess kann u.a. die Notifizierung von Kunden, das Deaktivieren von Servern, Bereitstellung eines Patch-Plans, etc. beinhalten.

Diese Vorkehrungen müssen nicht nur den eigenen Code, sondern auch Schwachstellen in verwendeten Fremdbibliotheken und Frameworks beinhalten. Angriffe gegen verwendete Bibliotheken/Frameworks (eine Form der supply-chain attacks) nahmen in letzter Zeit zu.

\section{Security Principles}

Während sich Technologien und Architekturen permanent wandeln und verändern, gibt es Sicherheitsprinzipien die quasi allgemeingültig sind. Einige dieser werden in diesem Kapitel erläutert.

\subsection{Minimalprinzip}

Die Applikation sollte nur jene Operationen und Funktionen beinhalten, die für die Erfüllung der Kundenanforderungen zwingend notwendig sind. Alle weiteren Funktionen und Operationen sollten deaktiviert bzw. entfernt werden.

Durch diese Reduktion des Funktionsumfangs wird implizit die Angriffsfläche verringert und dadurch Angriffe erschwert. \textit{Was nicht vorhanden ist, kann nicht angegriffen werden}. Zusätzlich wird dadurch der langfristige Wartungsaufwand reduziert.

Die Minimierung kann und sollte an mehreren Stellen durchgeführt werden, einige Beispiele:

\begin{itemize}
	\item Reduktion benötigter Operationen: ist eine Operation wirklich für den Kunden notwendig oder könnte der Kundenwunsch mit bereits implementierten Operationen ebenso befriedigt werden?
	\item Reduktion der gesammelten und gespeicherten Daten: was ist das minimale Datenset, dass für die Bereitstellung der Operationen benötigt wird. Dies entspricht auch der Datenminimierung die durch die DSGVO vorgeschrieben wird. Hier gibt es einen Wandel der Kultur: von big-data (alles speichern, vielleicht kann man das später verwenden) Richtung toxic-data (Daten sind gefährlich, wie komme ich mit möglichst wenig Daten aus).
	\item Komponentenebene: welche Komponenten sind für den Betrieb notwendig?
	\item Funktionale Ebene: welche Funktionen und Features können innerhalb von Komponenten deaktiviert werden?
\end{itemize}

\subsubsection{Security Misconfiguration}

Die OWASP Top 10 sprechen in diesem Zusammenhang auch gerne von \textit{Security Misconfiguration}.

Wie bereits erwähnt, ist die Grundidee, dass im Produktionsbetrieb nur Komponenten und Features vorhanden sind, die auch für die Umsetzung eines Kundenwunsches benötigt werden.

Beispiele für Software, die nicht am Server vorgefunden werden sollte:

\begin{itemize}
	\item Entwicklungstools wie phpmyadmin. Diese besitzen meistens getrennte Zugangsdaten (verwenden also nicht die Zugangsdaten/Berechtigungen der Web-Applikation) und sind daher potentiell ein \textit{alternate channel} über den auf eine Webapplikation zugegriffen werden kann.
	\item Debug Mode bei verwendeten Frameworks, dieser erlaubt teilweise im Fehlerfall die Verwendung von interaktiven Shells direkt innerhalb der Webapplikation. Dies würde es einem Angreifer erlauben, direkt Programmcode abzusetzen.
	\item Debug Toolbars bei Verwendung von Frameworks. Diese erlauben es zeitweise die letzten Sessions aller Benutzer anzuzeigen und erleichtern auf diese Weise Identity Theft.
	\item Stacktraces mit Detailinformationen im Produktivbetrieb. Ein normaler Anwendern kann mit diesen Informationen nichts anfangen und ein Angreifer kann durch sie genaue Systeminformationen (Bibliotheksversionen, Pfade, etc.) erhalten.
	\item phpinfo.php liefert genaue Informationen über die verwendete PHP-Version, verfügbare Module, System- und Konfigurationsinformationen die im Produktivbetrieb nicht öffentlich verfügbar sein müssen.
\end{itemize}

Beispiele für Metadaten, die nicht am Server vorgefunden werden sollten:

\begin{itemize}
	\item Beispielscode (/example Directory). Dieser kann zeitweise ebenso Sicherheitsfehler enthalten und auf diese Weise Zugang zu dem System erlauben.
	\item .git, .svn Verzeichnisse: diese beinhalten den gesamten Source-Code samt Versionshistory. Ein Angreifer kann auf diese Weise interne Credentials erhalten, als auch den verwendeten Source Code analysieren.
	\item .DS\_Store beinhaltet Metainformationen des MacOS-Filebrowsers.
	\item Credentials im Dateisystem oder in Repositories. Da Repositories häufig auf öffentlichen Webservern gespeichert wird (z. B. private gitlab/githab/bitbucket Repositories) gespeichert wird, können diese im Falle einer Fehlkonfiguration auch potentiell öffentlich zugreifbar gemacht werden. In diesem Fall besitzt ein Angreifer credentials mit denen er potentiell auf sensible Aktivitäten oder Daten zugreifen kann.
	\item Backup files (.bak, .tmp) innerhalb des Dateisystems, diese werden z. B. durch Texteditoren angelegt. Wird z. B. auf einem PHP-System eine PHP-Datei am Webserver abgelegt und ein Angreifer greift darauf zu, wird der Code am Server ausgeführt und der Angreifer erhält nur das Ergebnis der Operation. Falls der Angreifer eine Backup-Datei am Server findet, kann er auf diese zugreifen, herunterladen und analysieren und kann auf diese Weise Fehler innerhalb des Source Codes suchen.
\end{itemize}

\subsection{Least Privilege}

Jeder Benutzer und jede Funktion sollte nur jene minimalen Rechte und Privilegien besitzen, die für die Ausführung seiner Ausgabe zwingend benötigt werden. Jerome Saltzer definierte diesen, als Least Privilege bekannten, Ansatz als:

\begin{quote}
Every program and every priviledged user of the system should operate using the least amount of priviledge necessary to complete the job.
\end{quote}

Wird dieses Prinzip bereits während des Designs beachtet, fürht dies zumeist zu Systemen, welche aus mehreren Komponenten bestehen. Diese Komponenten kommunizieren über wohl-definierte Interfaces und können nicht ``direkt'' auf die Daten anderer Komponenten zugreifen. Dies verbessert die Testbarkeit der einzelnen Komponenten, da diese getrennt voneinander überprüft werden können. Aus Sicherheitssicht ist diese Architektur ebenso stark zu bevorzugen da eine kompromittierte Komponente nicht automatisch ein kompromittiertes Gesamtsystem zur Folge hat.

Um diese Trennung zu ermöglichen, müssen Komponenten mit unterscheidbaren Identitäten und mit zuweisbaren Ressourcen betrieben werden. Dies inkludiert sowohl Benutzer- und Zugriffsrechte als auch Entitlements auf Ressourcen (RAM, CPU, Speicher, Netzwerkbandbreite). Weiters inkludiert dies Netzwerkzugriffsrechte: die Applikation sollte nur auf jene remote Server zugreifen können, die auch wirklich zwingend für den Betrieb notwendig sind.

\subsection{Separation of Duties}

Separation of Duties besagt, dass zur Ausführung einer Operation die Zustimmung von mehr als einer Person benötigt wird. Ein klassisches Beispiel hierfür wäre die Aktivierung eines Atomstprengkopfes für das mehrere Personen ihre Zustimmung geben müssen. Das Ziel von Separation of Duties ist auf der einen Seite die Vermeidung von Insider-Threats, auf der anderen Seite soll dadurch die Entdeckungsrate von nicht-gewollten Aktivitäten erhöht werden. Grundsätzlich sollte ein kompromittierter Benutzer nicht die Möglichkeit besitzen, das Gesamtsystem zu korrumpieren.

Eine Anwendung dieser Idee ist das Vier-Augen-Prinzip bei dem sensible Operationen vor Ausführung zuerst durch zumindest zwei Personen bestätigt werden müssen.

Um diese Prinzipien anwenden zu können, müssen Anwender zweifelsfrei identifiziert, authentifiziert und für die auszuführende Operatione authorisiert werden. Aus diesem Grund werden Mehr-Faktor-Authentifizierungslösungen häufig im Umfeld des Separation of Duties Prinzips gefunden.

\subsection{Defense in Depth/Hardening}

Das Zwiebelmodel der Sicherheit vergleicht die Gesamtsicherheit einer Applikation mit einer Zwiebel. Im Inneren der Zwiebel befindet sich das schützenswerte Gut (Daten, Operationen), rundherum gibt es einzelne Sicherheitsschichten, analog zu den Schichten einer Zwiebel. Solange zumindest eine Schutzschicht vorhanden ist, ist die Sicherheit des Gesamtsystems gewährleistet.

Essentiell ist, dass die einzelnen Schutzschichten voneinander unabhängig sind. Würde die gleiche Schutzschicht mehrfach verwendet werden (z. B. zweimal die gleiche Web-Application-Firewall mit dem identen Regelwerk der Applikation vorgeschalten werden), würde ein Fehler in einer Schutzschicht automatisch auch den Schutz der zweiten Schutzschicht neutralisieren.

Zusätzlich zum erhöhten Schutz des schützenswerten Gutes wird durch die Zwiebelschichten auch Zeit im Fehlerfall erkauft. Da das System noch nicht vollständig kompromittiert ist, besteht z. B. Zeit die Auswirkungen eines potentiellen Updates zu testen.

\subsection{Fail-Open vs. Fail-Closed}

Fail-Open (auch Fail-Safe genannt) und Fail-Close (auch Fail-Secure genannt) beschreiben das Verhalten eines Systems im Fehlerfall. Bei Fail-Open wird die Operation durchgeführt, bei Fail-Close wird diese verhindert.

Die Definition des gewünschten Verhaltens kann nur durch den Kunden geschehen. Beispiel: ein Smart-Türschloss welches über eine Mobilapplikation gesteuert werden kann. Das Verhalten im Falle eines Batteriefehlers kann unterschiedlich implementiert werden. In einigen Fällen (Notausgang) wäre es sinnvoll, das Schloss zu öffnen; in einigen Fällen (Tresor) wäre es sinnvoll, das Schloss zu blockieren. Diese Auswahl kann nur vom Kunden durchgeführt werden.

\subsection{No-Go: Security by Obscurity}

Die Sicherheit eines Systems darf niemals von dessen Intransparenz abhängig sein. Ein besserer Ansatz ist z. B. Shannons: \textit{The Enemy Knows the System}.

Ein motivierter Angreifer besitzt zumeist Möglichkeiten die Intransparenz zu lüften:
\begin{itemize}
	\item Kauf und Reverse-Engineering der Software
	\item Diebstahl eines Systems
	\item Verlust der Obscurity durch Unfall (z. B. Selfies mit sichtbaren Schlüsseln im Hintergrund)
\end{itemize}

Analog gibt es in der Kryptographie das Kerckhoffsche Prinzip: die Sicherheit eines Algorithmus darf nur von der Geheimhaltung des Schlüssels und nicht durch die Geheimhaltung des Algorithmus abhängig sein.

\subsection{Keep it Simple and Stupid (KISS)}

\textit{Complexity is the enemy of security}. Ein komplexes System mit vielen Komponenten bzw. Interaktionen zwischen Komponenten besitzt automatisch eine größere Angriffsfläche und bieten daher Angreifern mehr Möglichkeiten.

Man sollte Simplicity nicht mit primitiven Lösungen verwechseln. Der Grundgedanke stammt aus dem Lockheed-Martin Skunk Works Umfeld, also jenem Ingenieursteam welches einige der hoch-technologischsten Aufklärungsflugzeuge des Kalten Krieges entwurf (U2, SR-71).

\section{Denial-of-Service Angriffe}

Denial-of-Service Angriffe zielen darauf ab, die Verfügbarkeit einer Applikation zu beeinträchtigen. Dadurch kann der Dienst nicht mehr benutzt bzw. konsumiert werden und dem Betreiber entstehen Kosten, z. B. Verdientsentgang druch einen ausgefallenen Webshop.

Ein DoS-Angriff zielt entweder auf eine Applikations-bezogene Ressource wie z. B. erlaubte Verbindungen pro Applikationsbenutzer oder eine fundamentale Systemresource wie z. B. CPU-Zeit, Speicher oder Netzwerkbandbreite ab. Als Applikationsentwickler kann man bei Ressourcen-intensiven Operationen mittels Rate-Limits die Situation leicht entschärfen.

In diesem Dokument wird nicht tiefer auf DoS-Angriffe eingegangen, da diese quasi die Holzhammermethode darstellen. Gerade gegenüber Angriffen gegen die Netzwerkbandbreite kann nur über kommerzielle Cloud- bzw. Rechenzentrenbetreiber entgegengewirkt werden. Diese sind kostspielig und es entsteht eine Asymmetrie: die Abwehr des Angriffs ist kostspieliger als der Angriff selbst. Somit wird aus einem technischen DoS ein monetärer DoS.

\section{Security und Usability}

Es gibt das Vorurteil, dass Sicherheit und Usability konträr sind. Während dies in wenigen bedauerlichen Einzelfällen gegeben sein kann, sollte dies nicht als Pauschalausrede zur Vermeidung vom Selbst-Denken missbraucht werden.

Der Benutzer will primär eine Aufgabe erledigen. Im Zuge der Erledigung dieser Aufgabe sollte Sicherheit nicht im Weg stehen. Stattdessen sollte der offensichtliche Weg der Aufgabenerledigung sicher implementiert sein und den Benutzer über einen sicheren Weg zur Erledigung der Aufgabe leiten. Falls sicherheitsrelevante Benutzerentscheidungen notwendig sind, sollten diese möglichst früh erfolgen --- wird dies während der Abarbeitung einer Aufgabe durchgeführt, kann der Benutzer so fokussiert sein, dass die Sicherheitsentscheidung nur peripher beachtet wird.

Ebenso sollte der Benutzer nicht mit irrelevanten Fragen bombardiert werden. Tests zeigen, dass dadurch nur der ``Meldung-wegklicken''-Reflex konditioniert wird. Die Willigkeit eines Benutzers, auf Sicherheit Rücksicht zu nehmen ist begrenzt, vergleichbar mit einer Batterie. Wenn diese erschöpft ist, wird weniger (oder gar keine) Rücksicht auf die Security genommen.

Ein besserer Weg ist es, per default sichere Prozesse zu implementieren und im Bedarfsfall unsichere Operationen druch den Benutzer explizit zu erlauben. Die dabei verwendeten Benutzerinteraktionen sollten dem NEAT-Prinzipien genügen:

\begin{itemize}
	\item Necessary: kann die Applikation, anstatt den Benutzer zu fragen, das Problem auf eine andere sichere Art und Wiese lösen?
	\item Explained: besitzt der Benutzer das notwendige Wissen um eine informierte Entscheidung zu treffen?
	\item Actionable: kann der Benutzer überhaupt sinnvoll auf die dargestellte Meldung reagieren?
	\item Tested: ist die Meldung innerhalb der UX sinnvoll und wurde getestet, ob sie in jeglicher Form von Benutzerfluss sinnvoll ist?
\end{itemize}

Im Zuge der DSGVO/GDPR wurde bestimmt, dass Software \textit{secure by design and default} sein muss. Dies bedeutet, dass Software die Möglichkeit einer sicheren Konfiguration bieten muss und diese im Auslieferungszustand auch sicher konfiguriert sein muss. Ein Beispiel das dagegen verstößt wäre der Einsatz von Default-Passwörtern.

\section{Reflektionsfragen}

\begin{enumerate}
	\item Was versteht man unter einem Threat Model, welche Elemente sollten vorhanden sein (1-2 Sätze Beschreibung pro Element)
	\item Erläutere das Minimalprinzip mit zumindest drei Beispielen für jenes.
	\item Erläutere Least Privilege und Separation of Duties.
	\item Erläutere Defense in Depth.
	\item Welche Maßnahmen sollten im Zuge des Secure Development Lifecycles betrachtet werden? Erläutere einige der Maßnahmen.
	\item Erkläre den Unterschied zwischen Fail-Open und Fail-Closed.
\end{enumerate}
